{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 5\n",
    "\n",
    "Para la aceptación de un artículo en un congreso se definen las siguientes\n",
    "especificaciones que deben cumplir y recomendaciones de escritura:  \n",
    "\n",
    "**título**:  \n",
    " - 10 palabras como máximo  \n",
    "\n",
    "cada oración del **resumen**:  \n",
    " - hasta 12 palabras: fácil de leer  \n",
    " - entre 13-17 palabras: aceptable para leer  \n",
    " - entre 18-25 palabras: difícil de leer  \n",
    " - mas de 25 palabras: muy difícil\n",
    "\n",
    "Es importante destacar que los números no se consideran palabras al momento del\n",
    "análisis por su facilidad de lectura.  \n",
    "Dado un artículo en formato string, defina si cumple las especificaciones del título y\n",
    "cuántas oraciones tiene de cada categoría. El formato estándar en que recibe el string\n",
    "tiene la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"\"\"título: Experiences in Developing a Distributed Agentbased\n",
    "Modeling Toolkit with Python Version 3\n",
    "resumen: Distributed agent-based modeling (ABM) on high-performance\n",
    "computing resources provides the promise of capturing unprecedented\n",
    "details of large-scale complex systems. However, the specialized\n",
    "knowledge required for developing such ABMs creates barriers to wider\n",
    "adoption and utilization. Here we present our experiences in\n",
    "developing an initial implementation of Repast4Py, a Python-based\n",
    "distributed ABM toolkit. We build on our experiences in developing ABM\n",
    "toolkits, including Repast for High Performance Computing (Repast\n",
    "HPC), to identify the key elements of a useful distributed ABM\n",
    "toolkit. We leverage the Numba, NumPy, and PyTorch packages and the\n",
    "Python C-API to create a scalable modeling system that can exploit the\n",
    "largest HPC resources and emerging computing architectures.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo se debe informar:  \n",
    " - título: not ok\n",
    " - Cantidad de oraciones fáciles de leer: 1, aceptables para leer: 2, dificil de leer: 1,\n",
    "muy difícil de leer: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, extraemos de la cadena del titulo y las oraciones del resumen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributed agent-based modeling (ABM) on high-performance computing resources provides the promise of capturing unprecedented details of large-scale complex systems\n",
      "However, the specialized knowledge required for developing such ABMs creates barriers to wider adoption and utilization\n",
      "Here we present our experiences in developing an initial implementation of Repast4Py, a Python-based distributed ABM toolkit\n",
      "We build on our experiences in developing ABM toolkits, including Repast for High Performance Computing (Repast HPC), to identify the key elements of a useful distributed ABM toolkit\n",
      "We leverage the Numba, NumPy, and PyTorch packages and the Python C-API to create a scalable modeling system that can exploit the largest HPC resources and emerging computing architectures\n"
     ]
    }
   ],
   "source": [
    "article = article.replace('\\n', ' ')\n",
    "tit_end_index = article.find(\"resumen: \")\n",
    "titulo = article[8:tit_end_index]\n",
    "\n",
    "resumen = article[tit_end_index + 9:].strip()\n",
    "sentences = resumen.split('.')\n",
    "sentences = [sentence.strip() for sentence in sentences if len(sentence) > 0]\n",
    "for sentence in sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos la funcion cantPalabras() que dada una cadena, cuenta las palabras sin tener en cuenta los numeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "titulo: not ok\n",
      "Cantidad de oraciones fáciles de leer: 0, aceptables para leer: 2, dificil de leer: 1, muy difícil de leer: 2\n"
     ]
    }
   ],
   "source": [
    "import funciones\n",
    "\n",
    "if (funciones.cantPalabras(titulo) <= 10):\n",
    "    print(funciones.cantPalabras(titulo))\n",
    "    print('titulo: ok')\n",
    "else:\n",
    "    print('titulo: not ok')\n",
    "\n",
    "faciles = 0\n",
    "aceptables = 0\n",
    "dificiles = 0\n",
    "muy_dificiles = 0\n",
    "\n",
    "for sentence in sentences:\n",
    "    palabras = funciones.cantPalabras(sentence)\n",
    "    if palabras <= 12:\n",
    "        faciles += 1\n",
    "    elif palabras <= 17:\n",
    "        aceptables += 1\n",
    "    elif palabras <= 25:\n",
    "        dificiles += 1\n",
    "    else:\n",
    "        muy_dificiles += 1\n",
    "print(f'Cantidad de oraciones fáciles de leer: {faciles}, aceptables para leer: {aceptables}, dificil de leer: {dificiles}, muy difícil de leer: {muy_dificiles}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
